{
 "metadata": {
  "name": "",
  "signature": "sha256:ac2103ca0896d228c4c56d2ac082556cb9c7abb1684ecc013a40e078a96ea32b"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Voxelwise Analyses: Intersubject Correlation\n",
      "=============================================\n",
      "By making the width of the searchlight 0, we can get a single center for each voxel.\n",
      "This will allow us to perform a mass univariate analysis.\n",
      "In the dataset we are using, we have a list with 3 participants.\n",
      "Each participant is a 1x1x15 brain, with 10 timepoints.\n",
      "Thus, the overall dimensions are `3` (in a list) x `1x1x15x10` (in numpy arrays).\n",
      "The following code below grabs each voxel, and then calculates the inter-subject correlation (explained below)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load Data\n",
      "---------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"setup data\"\"\"\n",
      "import numpy as np\n",
      "data = [sub for sub in np.load('data/example_corr_data.npy')]\n",
      "\n",
      "data[0].shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "(1, 1, 15, 10)"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The one thing to note here is that we made data a list, rather than keeping it as a numpy array.\n",
      "When it receives a list, pysearchlight will assume that each entry is a separate subject.\n",
      "As a result, for each searchlight, it will return a list of the form..\n",
      "\n",
      "```\n",
      "[searchlight for subject 1, searchlight data for subject 2, ... ]\n",
      "```\n",
      "\n",
      "This lets us run more complex, cross-subject searchlights.\n",
      "However, another consequence that we'll take advantage of here is that it lets us run the simpler case, where we do something within each voxel individually (but across subjects)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create Centers for Searchlight\n",
      "------------------------------\n",
      "To create searchlight centers, we make a simple mask with the same spatial dimensions as our data.\n",
      "In this case, we want every voxel, so it's all ones.\n",
      "Next, we indicate that cutoff is 0, to get searchlights that consist only of the center voxel (since it has a distance of 0 from itself).\n",
      "\n",
      "Finally, we feed the centers to the searchlight, along with a function for calculating inter-subject correlation. In this case, we define the inter-subject correlation as the average pairwise correlation..\n",
      "\n",
      "$$mean(\\sum_{i=1}^{n}{\\sum_{j=i+1}^{n}{cor(\\text{subject}_i, \\text{subject}_j)}})$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"setup searchlight centers and run ISC\"\"\"\n",
      "from pysearchlight import gen_searchlight_ind, run_searchlight\n",
      "# get center for each searchlight\n",
      "mask = np.ones([1,1,15])\n",
      "kwargs = dict(cutoff=0,shape=mask.shape)\n",
      "centers = gen_searchlight_ind(thr=1, mask=mask, **kwargs)\n",
      "\n",
      "# calculate ISC\n",
      "def avg_pairwise_corr(d):\n",
      "    \"\"\"Calculate average pairwise correlation\"\"\"\n",
      "    corrs = np.corrcoef(np.vstack(d))\n",
      "    return corrs[np.tril_indices_from(corrs, -1)].mean()\n",
      "\n",
      "result = run_searchlight(centers, avg_pairwise_corr, data, center_kwargs=kwargs)\n",
      "result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "outputting to:\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "{(0, 0, 0): -0.40000000000000008,\n",
        " (0, 0, 1): -0.30000000000000021,\n",
        " (0, 0, 2): -0.19999999999999996,\n",
        " (0, 0, 3): -0.10000000000000014,\n",
        " (0, 0, 4): -2.2204460492503146e-16,\n",
        " (0, 0, 5): 0.099999999999999978,\n",
        " (0, 0, 6): 0.19999999999999971,\n",
        " (0, 0, 7): 0.3000000000000001,\n",
        " (0, 0, 8): 0.40000000000000008,\n",
        " (0, 0, 9): 0.4999999999999995,\n",
        " (0, 0, 10): 0.59999999999999953,\n",
        " (0, 0, 11): 0.69999999999999962,\n",
        " (0, 0, 12): 0.79999999999999982,\n",
        " (0, 0, 13): 0.8999999999999998,\n",
        " (0, 0, 14): 0.99999999999999967}"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Why on Earth would I do This?\n",
      "-----------------------------\n",
      "Because you are a glutten for punishment.\n",
      "\n",
      "(or you want to use the convenient command line functions that pysearchlight has for breaking it into many small jobs!)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<br>\n",
      "<br>\n",
      "<br>\n",
      "<br>\n",
      "<hr>\n",
      "#### Tests (feel free to ignore)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"test that correlations are -.4, -.3, ..., .9, 1\"\"\"\n",
      "assert np.allclose(np.array([result[(0,0,ii)] for ii in range(15)]),\n",
      "                            np.arange(-.4, 1.1, .1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"test that results are equivalent to looping over data\"\"\"\n",
      "n_vox = data[0].shape[-1]\n",
      "looped = []\n",
      "for ii in range(n_vox): \n",
      "    isc = avg_pairwise_corr([entry[0,0,ii] for entry in data])\n",
      "    looped.append(isc)\n",
      "\n",
      "assert np.allclose([result[(0,0,ii)] for ii in range(n_vox)],\n",
      "                   looped)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    }
   ],
   "metadata": {}
  }
 ]
}